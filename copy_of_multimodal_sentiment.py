# -*- coding: utf-8 -*-
"""Copy of MultiModal Sentiment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k0FBahQdmJvdDA3tXYZc6_UETTSsP8Q-
"""

!pip install av bitsandbytes

!pip install -U bitsandbytes

# import av
import torch
import numpy as np
from transformers import LlavaNextVideoForConditionalGeneration, LlavaNextVideoProcessor, BitsAndBytesConfig

llava_7 ="llava-hf/LLaVA-NeXT-Video-7B-hf"
llava_13 ="llava-hf/LLaVA-NeXT-Video-13B-hf"
pnevision_7="llava-hf/llava-onevision-qwen2-7b-ov-hf"

def next_model(type):
    quantization_config = BitsAndBytesConfig(
        load_in_4bit=True,  # Mengaktifkan quantization 4-bit
        bnb_4bit_quant_type="nf4",  # Jenis quantization menggunakan NF4
        bnb_4bit_compute_dtype=torch.float16  # Precision komputasi dalam float16
    )
    # Memuat model dengan konfigurasi quantization
    model = LlavaNextVideoForConditionalGeneration.from_pretrained(
        type,
        quantization_config=quantization_config,  # Menggunakan konfigurasi quantization
        device_map="auto"  # Pemetaan otomatis ke GPU/CPU
    )
    processor = LlavaNextVideoProcessor.from_pretrained(type)
    print(f"Model Llava-NEXT {type} berhasil dimuat.")
    return model, processor
def onevision_model(type):
    quantization_config = BitsAndBytesConfig(
        load_in_4bit=True,  # Mengaktifkan quantization 4-bit
        bnb_4bit_quant_type="nf4",  # Jenis quantization menggunakan NF4
        bnb_4bit_compute_dtype=torch.float16  # Precision komputasi dalam float16
    )
    # Memuat model dengan konfigurasi quantization
    model = LlavaOnevisionForConditionalGeneration.from_pretrained(type, quantization_config=quantization_config, device_map="auto")
    processor = AutoProcessor.from_pretrained(type)
    print(f"Model Llava-onevision {type} berhasil dimuat.")
    return model, processor

def read_video_pyav(container, indices):
    """
    Decode video frame dengan PyAV.
    Args:
        container: PyAV container untuk video.
        indices: Indeks frame yang akan diambil.
    Returns:
        result: Numpy array frame video (shape: num_frames, height, width, 3).
    """
    frames = []
    container.seek(0)
    start_index = indices[0]
    end_index = indices[-1]
    for i, frame in enumerate(container.decode(video=0)):
        if i > end_index:
            break
        if i >= start_index and i in indices:
            frames.append(frame)
    return np.stack([x.to_ndarray(format="rgb24") for x in frames])

import av
import numpy as np


def preprocess_video(row):
    formatted_path = f"/content/drive/MyDrive/Multimodal/new/{row['path']}.mp4"
    container = av.open(formatted_path)  # Open video container
    total_frames = container.streams.video[0].frames
    indices = np.linspace(0, total_frames - 1, 10).astype(int)  # Pilih 10 frame dari video

    print(f"Processing video: {row['path']}.mp4")  # Menampilkan nama video yang sedang diproses

    video_tensor = read_video_pyav(container, indices)  # Call read_video_pyav with the container

    for i, idx in enumerate(indices, start=1):
        print(f"Extracting frame {i}/{len(indices)}")  # Menampilkan progres ekstraksi frame

    container.close()  # Close the container after use
    return video_tensor

def predict_sentiments(model, processor, dataset):
    """Melakukan prediksi sentimen dari dataset yang berisi video dan transkrip."""
    results = []

    for index, row in dataset.iterrows():
        transcript = row["transcript"]
        video_tensor = row["video_tensor"]
        emotion=row["emotion"]

        conversation = [
            {
                "role": "system",
                "content": [
                    {"type": "text", "text": """
                    Anda adalah asisten yang bertugas untuk menentukan sentimen (positif, netral, atau negatif) berdasarkan video, dialog, dan emotion dari karakter pada vidio.
                    Kriteria:
                    1. Sentimen ditentukan berdasarkan video
                    2. Sentimen juga dipengaruhi oleh teks dialog dan emotion karakter dalam video.
                    Berikan respons berupa Positive, Neutral, atau Negative tanpa penjelasan.
                    """},
                ],
            },
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": f"""
                Dialog dari video:
                "{transcript}"
                Berikut emotion dari karakter dalam video:{emotion}
                """},
                    {"type": "video"},
                ],
            },
        ]

        prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)

        inputs = processor(
            text=prompt,
            videos=video_tensor,
            return_tensors="pt",
            padding=True,
            truncation=True,
        )
        inputs = {key: value.to(model.device) for key, value in inputs.items()}

        output = model.generate(**inputs, max_new_tokens=250)
        result = processor.batch_decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)
        print("Memprediksi Vidio: ",row["path"])
        results.append({"transcript": transcript, "predicted_sentiment": result[0]})

    results_df = pd.DataFrame(results)
    results_df.to_csv("prediksi.csv", index=False)
    return results_df

from google.colab import drive
drive.mount('/content/drive')
import pandas as pd

def Read_data(path,cleanKolom=True):
    data=pd.read_csv(path)
    print("\n===========================================================\n")
    print("DATA AWAL : ")
    print("\n===========================================================\n")
    print(data.info())
    if cleanKolom:
        data = data.drop(['Label1',"Label2"], axis=1)
    data= pd.DataFrame(data)
    print("\njumlah data kosong", data.isnull().sum())
    data = data.dropna()

    data['sentiment'] = data['sentiment'].str.lower().str.strip().str.replace(r'\W', '', regex=True)
    mapping = {'negative': 'Negative', 'positive': 'Positive', 'neutral': 'Neutral', 'netral': 'Neutral'}
    data['sentiment'] = data['sentiment'].map(mapping)
    dataclean=data

    sentiment_counts = dataclean['sentiment'].value_counts()

    plt.figure(figsize=(5, 4))
    sns.countplot(x='sentiment', data=dataclean)
    plt.title('Sentiment Label Distribution')
    plt.xlabel('Sentiment Label')
    plt.ylabel('Count')
    print("\n===========================================================\n")
    print("HASIL FUNCTION : ")
    print("\n===========================================================\n")
    print(dataclean.info())
    print("\n===========================================================\n")
    print(sentiment_counts)
    print("\n===========================================================\n")
    plt.show()
    print("\n===========================================================\n")
    print(dataclean)

    return dataclean

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

def vidiotensor_predict(dataclean):
    df=dataclean
    df['video_tensor'] = df.apply(preprocess_video, axis=1)
    print("\n===========================================================\n")
    print("\nJumlah Data Tensor kosong: ",df['video_tensor'].isnull().sum())
    print("\n===========================================================\n")
    predictes=predict_sentiments(model, processor, df)

    predictes['predicted_sentiment']=predictes['predicted_sentiment'].str.extract(r'ASSISTANT:\s*(Positive|Neutral|Negative)', expand=False)
    hasil = pd.merge(df, predictes[['transcript', 'predicted_sentiment']], on='transcript', how='left')
    hasil_akhir=hasil[["video_id",	"transcript",	"path",	"emotion",	"sentiment","predicted_sentiment"]]
    print("\nJumlah Data Prediksi kosong yang dihapus: ",hasil_akhir['predicted_sentiment'].isnull().sum())
    hasil_akhir=hasil_akhir.dropna()
    print("\n===========================================================\n")
    print(hasil_akhir.info())
    hasil_akhir.to_csv('hasil_akhir.csv', index=False)
    print("\n===========================================================\n")
    print("\nTabel Akhir :\n",hasil_akhir)

    accuracy = accuracy_score(hasil_akhir["sentiment"], hasil_akhir["predicted_sentiment"])
    print("\n===========================================================\n")
    print(f"Akurasi Model: {accuracy:.2%}")

    print("\nClassification Report:\n")
    print(classification_report(hasil_akhir["sentiment"], hasil_akhir["predicted_sentiment"], target_names=["negative", "neutral", "positive"]))

    cm = confusion_matrix(hasil_akhir["sentiment"], hasil_akhir["predicted_sentiment"], labels=["Negative", "Neutral", "Positive"])
    print("\n===========================================================\n")
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Negative", "Neutral", "Positive"], yticklabels=["Negative", "Neutral", "Positive"])
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.title("Confusion Matrix")
    plt.show()

    return hasil_akhir

path="/content/drive/MyDrive/Multimodal/Uji/eps3_20frames.csv"

data=Read_data(path,cleanKolom=True)

model, processor = model(model7)

akhir=vidiotensor_predict(data)

"""## 5 Frames settting GPT -- 7B"""

path="/content/drive/MyDrive/Multimodal/Uji/eps3_5frames.csv"

data=Read_data(path,cleanKolom=True)

model, processor = model(model7)

akhir=vidiotensor_predict(data)

"""##10 Frames GPT setting -- 7B Model"""

path="/content/drive/MyDrive/Multimodal/Uji/eps3_10frames.csv"

data=Read_data(path,cleanKolom=True)

model, processor = model(model7)

akhir=vidiotensor_predict(data)

data

data.info()

akhir.info()